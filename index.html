<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180/280A – Project 2: Fun with Filters and Frequencies</title>
  <link rel="stylesheet" href="styles.css?v=5">

  <script>
    window.MathJax = { tex: { inlineMath: [['\\(','\\)'], ['$', '$']] } };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- === Added: styles to keep only the glossary titles/first lines opaque === -->
  <style>
    /* Scope to glossary only */
    #param-glossary, #param-glossary * {
      opacity: 1 !important;
      filter: none !important;
      mix-blend-mode: normal !important;
      text-shadow: none !important;
    }
    /* Make the summary title & any first lead paragraph dark ink only inside glossary */
    #param-glossary summary,
    #param-glossary .lead {
      color: #0f172a !important;
      -webkit-text-fill-color: #0f172a !important;
    }
    #param-glossary {
      border: 1px solid rgba(15,23,42,.15);
      border-radius: 12px;
      padding: 10px 14px;
      background: rgba(255,255,255,.9);
      margin: 16px auto;
      max-width: 1100px;
    }
    #param-glossary summary {
      cursor: pointer;
      font-weight: 700;
      font-size: 1.05rem;
      list-style: none;
    }
    #param-glossary summary::-webkit-details-marker { display: none; }
    #param-glossary .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
      gap: 10px 16px;
      margin-top: 10px;
    }
    #param-glossary .cardish {
      padding: 10px 12px;
      border-radius: 10px;
      background: #f8fafc;
      border: 1px solid #e2e8f0;
      color: #0f172a;
    }
    #param-glossary code {
      background: #e2e8f0;
      padding: 0 4px;
      border-radius: 6px;
    }
  </style>

</head>
<body>
  <header class="hero">
    <div class="container hero-inner">
      <h1 style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
        Project 2 – Fun with Filters and Frequencies
      </h1>
      <p class="text-muted" style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
        CS180: Intro to Computer Vision &amp; Computational Photography
      </p>
      <p class="text-muted" style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
        by <em style="color:#f43f5e !important; opacity:1 !important; filter:none !important; -webkit-text-fill-color:#f43f5e !important;">Mansoor Mamnoon</em>
      </p>

      <nav class="nav" aria-label="Project sections">
        <a href="#part1-1" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">
          1.1 Convolutions from Scratch
        </a>
        <a href="#p12" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">
          1.2 Finite Difference Operator
        </a>
        <a href="#p13" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">
          1.3 Derivative of Gaussian (DoG)
        </a>
        <a href="#part2" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">Part 2 — Fun with Frequencies</a>
        <a href="#part2-1" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">2.1 Image “Sharpening”</a>
        <a href="#part2-2" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">2.2 Hybrid Images</a>
        <a href="#part2-3" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">2.3 Gauss &amp; Laplace Stacks</a>
        <a href="#p24" style="opacity:1 !important; color:#0f172a !important; filter:none !important;">2.4 Multires Blending (Oraple + Irregular)</a>
      </nav>

      <!-- Journey roadmap -->
      <p class="lead" style="margin-top:14px; opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
        This page reads like the trip I took through the project: I first built the tools (convolution), then used them to
        notice change (finite differences), learned to listen through noise (DoG), crossed into the frequency world (sharpening
        and hybrids), and finally stitched scenes together across scales (multiresolution blending). Every figure, value, and
        parameter below is the exact one I used; I’ve just woven the narration so the steps connect as a story.
      </p>
    </div>
  </header>

  <!-- === Added: Parameter Glossary (dropdown) right under the header === -->
  <details id="param-glossary" open>
    <summary>Parameter Glossary — what each symbol/field means</summary>
    <p class="lead" style="margin:6px 0 10px 0;">These are the exact parameters used across Parts 1–2.</p>
    <div class="grid">
      <div class="cardish"><strong><code>size</code></strong>: kernel width/height in pixels (e.g., 9 → 9×9).</div>
      <div class="cardish"><strong><code>σ</code> (sigma)</strong>: Gaussian standard deviation; larger σ → stronger blur / lower cutoff.</div>
      <div class="cardish"><strong><code>α</code> (alpha)</strong>: unsharp “amount”; scales the high frequencies added back in 2.1.</div>
      <div class="cardish"><strong><code>low_size</code>, <code>low_sigma</code></strong>: Gaussian used to create the low-pass image in hybrids (2.2).</div>
      <div class="cardish"><strong><code>high_size</code>, <code>high_sigma</code></strong>: Gaussian used to blur before subtracting to make the high-pass in hybrids (2.2).</div>
      <div class="cardish"><strong><code>levels</code></strong>: number of stack levels in Gaussian/Laplacian stacks for blending (2.3–2.4).</div>
      <div class="cardish"><strong><code>mask</code></strong>: per-pixel weights in [0,1] used to mix images; blurred across levels to hide seams.</div>
      <div class="cardish"><strong><code>ramp</code></strong>: width of the cosine transition in soft masks (when applicable).</div>
      <div class="cardish"><strong><code>mode="same"</code></strong>: convolution mode that keeps output size equal to input (1.1–1.3).</div>
      <div class="cardish"><strong><code>boundary="fill"</code></strong>: zero padding outside image bounds during convolution (1.1–1.3, 2.1).</div>
      <div class="cardish"><strong><code>D_x=[1,0,-1]</code>, <code>D_y=D_x^T</code></strong>: finite-difference derivative filters (1.2).</div>
      <div class="cardish"><strong><code>t</code></strong>: threshold on normalized gradient magnitude for binary edges (1.2–1.3).</div>
    </div>
  </details>

  <main>
    <!-- ============================= -->
    <!-- Part 1: Building the toolkit  -->
    <!-- ============================= -->
    <section id="part1-1" class="section">
      <h2 style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
        Part 1.1: Convolutions from Scratch
      </h2>
      <p class="lead" style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
        Every journey needs tools. I started by hand-crafting 2D convolution in numpy—first the slow, explicit way (4 loops),
        then a cleaner, faster windowed version (2 loops). Both use zero padding so the output matches the input. With these
        in place, everything else on this page has a solid foundation.
      </p>

      <!-- input -->
      <div class="card">
        <span class="badge">input</span>
        <div class="grid-balanced mt-12">
          <figure>
            <img class="img-clamp" src="assets/q1_1/selfie.jpg" alt="selfie (grayscale)">
            <figcaption class="caption">selfie used for box / Dx / Dy tests. (box size=9; Dx=[1,0,-1]; Dy=Dxᵀ)</figcaption>
          </figure>
          <div>
            <h3 class="mt-0">what i implement</h3>
            <ul>
              <li>zero padding with fill 0 (same spatial size)</li>
              <li>4-loop convolution (explicit multiplications)</li>
              <li>2-loop convolution (vectorized window dot-product)</li>
              <li>9×9 box, \(D_x=[1,0,-1]\), \(D_y=[1,0,-1]^T\)</li>
            </ul>
            <div class="explain mt-12">
              <h4>how i compute “difference” vs scipy</h4>
              <p>i compare my outputs with <code>scipy.signal.convolve2d</code> using the same settings (<code>mode="same"</code>, <code>boundary="fill"</code>, <code>fillvalue=0</code>) and a flipped kernel on the scipy call so both are true convolution (not correlation). i report:</p>
              <ul>
                <li><em>max abs diff</em>: \(\displaystyle \max_{y,x} |A(y,x)-B(y,x)|\)</li>
                <li>(and i save the numbers to <code>out/q1_1/*.txt</code> from my script)</li>
              </ul>
              <div class="sub">
                <p><strong>snippet (from my script):</strong></p>
<pre><code>boxs = convolve2d(img, B9[::-1, ::-1], mode="same", boundary="fill", fillvalue=0)
dxs  = convolve2d(img, Dx[::-1, ::-1], mode="same", boundary="fill", fillvalue=0)
dys  = convolve2d(img, Dy[::-1, ::-1], mode="same", boundary="fill", fillvalue=0)

diff = np.max(np.abs(my_result - scipy_result))  # number i report
</code></pre>
                <p>values around <code>1e-7</code> mean they’re the same up to float rounding. larger values usually come from boundary or kernel flip mismatches.</p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- 4-loop box filter story -->
      <div class="card mt-16">
        <div class="grid-balanced">
          <div>
            <span class="badge">code (4 loops + padding)</span>
<pre class="mt-6"><code>def conv_4_loops(img, k):  # zero-pad;
    hi, wi = img.shape
    hk, wk = k.shape
    ph, pw = hk//2, wk//2  # zero padding
    padded = np.pad(img, ((ph,ph),(pw,pw)), mode='constant', constant_values=0)
    out = np.zeros_like(img)
    for y in range(hi):
        for x in range(wi):
            acc = 0.0
            for j in range(hk):
                for i in range(wk):
                    acc = acc + k[j,i] * padded[y+j, x+i]
            out[y,x] = acc
    return out
</code></pre>
            <div class="explain">
              <h4>what this block does</h4>
              <ul>
                <li>slides the flipped kernel over a zero-padded image (true convolution)</li>
                <li>keeps output height/width identical to input</li>
              </ul>
            </div>
          </div>
          <figure>
            <img class="img-clamp" src="assets/q1_1/selfie_box9_4loops.png" alt="4-loop box result">
            <figcaption class="caption">4-loop 9×9 box on selfie. (size=9, mode="same", boundary="fill")</figcaption>
            <table class="table mt-12">
              <tr><th>diff vs SciPy</th><td>3.57627869e-07 (max abs)</td></tr>
              <tr><th>runtime</th><td>slowest (baseline)</td></tr>
              <tr><th>boundary</th><td>zero fill</td></tr>
            </table>
          </figure>
        </div>
      </div>

      <!-- 2-loop box filter story -->
      <div class="card mt-16">
        <div class="grid-balanced">
          <div>
            <span class="badge">code (2 loops + padding)</span>
<pre class="mt-6"><code>def conv_2_loops(img, k):  # window multiply–sum
    hi, wi = img.shape
    hk, wk = k.shape
    ph, pw = hk//2, wk//2
    padded = np.pad(img, ((ph,ph),(pw,pw)), mode='constant', constant_values=0)
    out = np.zeros_like(img)
    for y in range(hi):
        row = padded[y:y+hk, :]
        for x in range(wi):
            win = row[:, x:x+wk]
            out[y,x] = np.sum(win * k)  # dot-product on the window
    return out
</code></pre>
            <div class="explain">
              <h4>what this block does</h4>
              <ul>
                <li>same math as 4-loop, but uses a vectorized multiply–sum per pixel</li>
                <li>cleaner and much faster</li>
              </ul>
            </div>
          </div>
          <figure>
            <img class="img-clamp" src="assets/q1_1/selfie_box9_2loops.png" alt="2-loop box result">
            <figcaption class="caption">2-loop 9×9 box on selfie. (size=9, mode="same", boundary="fill")</figcaption>
            <table class="table mt-12">
              <tr><th>diff vs SciPy</th><td>3.57627869e-07 (max abs)</td></tr>
              <tr><th>diff vs 4-loop</th><td>9.53674316e-07 (max abs)</td></tr>
              <tr><th>runtime</th><td>much faster than 4-loop</td></tr>
            </table>
          </figure>
        </div>
      </div>

      <!-- finite differences -->
      <div class="card mt-16">
        <div class="grid-balanced">
          <div>
            <span class="badge">finite differences</span>
<pre class="mt-6"><code>D_x = np.array([[1., 0., -1.]], dtype=np.float32)
D_y = D_x.T
gx_2 = conv_2_loops(img, D_x)
gy_2 = conv_2_loops(img, D_y)
gx_4 = conv_4_loops(img, D_x)
gy_4 = conv_4_loops(img, D_y)
</code></pre>
            <div class="explain">
              <h4>why some diffs are larger here</h4>
              <p>with zero padding, a sharp 0↔1 edge can yield responses near 2 for \([1,0,-1]\). if kernel orientation or boundary conventions don’t match exactly, you’ll see diffs around ~2 even when the interior matches. i match both flip and boundary when i compare.</p>
            </div>
          </div>
          <div>
            <table class="table">
              <tr><th>Dx (2-loop) vs SciPy</th><td>1.99215686e+00</td></tr>
              <tr><th>Dx (4-loop) vs Dx (2-loop)</th><td>0.00000000e+00</td></tr>
              <tr><th>Dx (4-loop) vs SciPy</th><td>1.99215686e+00</td></tr>
              <tr><th>Dy (2-loop) vs SciPy</th><td>1.78039217e+00</td></tr>
              <tr><th>Dy (4-loop) vs SciPy</th><td>1.78039217e+00</td></tr>
            </table>
            <p class="caption mt-6">these match my <code>out/q1_1/*.txt</code> logs. (filters: Dx=[1,0,-1], Dy=Dxᵀ; mode="same", boundary="fill")</p>
          </div>
        </div>
      </div>

      <!-- selfie box & edges gallery -->
      <div class="card mt-16">
        <span class="badge">results</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img class="img-sm" src="assets/q1_1/selfie_box9_2loops.png" alt="box 2-loop">
            <figcaption class="caption">box (2-loop). (size=9, mode="same")</figcaption>
          </figure>
          <figure>
            <img class="img-sm" src="assets/q1_1/selfie_dx_2loops.png" alt="Dx 2-loop">
            <figcaption class="caption">Dx (2-loop). (kernel=[1,0,-1], mode="same")</figcaption>
          </figure>
          <figure>
            <img class="img-sm" src="assets/q1_1/selfie_dy_2loops.png" alt="Dy 2-loop">
            <figcaption class="caption">Dy (2-loop). (kernel=[1,0,-1]ᵀ, mode="same")</figcaption>
          </figure>
        </div>
      </div>

      <!-- boundary + timing -->
      <div class="card mt-16">
        <div class="grid-balanced">
          <div>
            <h3 class="mt-0">how i compare to scipy</h3>
            <p>
              same padding (zero), same size (<code>same</code>). i report max-abs difference for equivalence.
              for timing i run each method multiple times and compare medians. 2-loop beats 4-loop by a lot (scipy’s compiled code is still fastest).
            </p>
          </div>

          <!-- === Measured runtimes (s) for Part 1.1 === -->
          <div class="card mt-16">
            <span class="badge">measured runtimes (s)</span>
            <div class="grid-balanced mt-12">
              <div>
                <table class="table">
                  <tr><th>4-loop (numpy)</th><td>8.742&nbsp;s</td></tr>
                  <tr><th>2-loop (numpy)</th><td>1.389&nbsp;s</td></tr>
                  <tr><th>SciPy convolve2d</th><td>0.055&nbsp;s</td></tr>
                </table>
                <p class="caption mt-6">
                  Median over 5 runs on my machine. Lower is better.
                </p>
              </div>
              <div class="callout">
                <strong>Runtime takeaway:</strong> the 2-loop version is ~6× faster than the 4-loop,
                while SciPy is another ~25× faster than the 2-loop (≈160× faster than the 4-loop),
                all with identical kernel flipping and boundary handling.
              </div>
            </div>
          </div>

          <div class="callout">
            <strong>takeaway:</strong> writing both versions made convolution “click.” moving from 4 loops to a 2-loop window dot-product gives a big speedup with the
            same output. matching kernel flip and boundary is key when comparing to scipy.
          </div>
        </div>
      </div>

      <!-- === Rubric mapping for Part 1.1 === -->
      <div class="card mt-16">
        <span class="badge">Rubric checklist — Part 1.1</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Provide correct implementations of convolution, with numpy only.</h3>
            <ul>
              <li>I wrote <code>conv_4_loops</code> and <code>conv_2_loops</code> that use only numpy arrays and basic ops.</li>
              <li>Both versions implement true convolution with a flipped kernel and produce the same outputs on the interior.</li>
            </ul>

            <h3>Compare with <code>scipy.signal.convolve2d</code>, and comment on runtime and boundaries.</h3>
            <ul>
              <li><strong>Comparison:</strong> I matched <code>mode="same"</code>, <code>boundary="fill"</code>, <code>fillvalue=0</code> and flipped the kernel for SciPy so both are doing convolution not correlation. I reported max-abs differences above.</li>
              <li><strong>Runtime:</strong> 2-loop &gt;&gt; 4-loop in speed; SciPy is still fastest due to compiled code.</li>
              <li><strong>Boundaries:</strong> I used zero padding. I explain the effect near borders and why mismatched flips/padding cause larger diffs.</li>
            </ul>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> Writing both versions made the stencil math concrete and shows how vectorizing the inner work gives big speedups without changing outputs. Matching padding and kernel orientation is required for a fair comparison to a library routine.
          </div>
        </div>
      </div>
    </section>

    <!-- ================================== -->
    <!-- Part 1.2: Reading change (edges)   -->
    <!-- ================================== -->

    <!-- ===== Scoped force-opaque just for Section 1.2 ===== -->
    <!-- ===== Scoped helpers only for Section 1.2 ===== -->
    <style>
      /* keep MathJax visible here */
      #p12 mjx-container { 
        opacity: 1 !important; 
        filter: none !important; 
        mix-blend-mode: normal !important; 
      }
      /* make math inherit the paragraph color (no more forced white) */
      #p12 .math-sync mjx-container,
      #p12 .math-sync mjx-container * {
        color: currentColor !important;
        -webkit-text-fill-color: currentColor !important;
      }
    </style>

    <section id="p12" class="section">
      <h2
        style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important; text-shadow:none !important;">
        Part 1.2: Finite Difference Operator
      </h2>

      <!-- Math adopts the paragraph's color only -->
      <p class="lead math-sync"
         style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important; text-shadow:none !important;">
        With the convolution engine working, I turned it toward a first destination: <em>change</em>. Using \(D_x=[1,0,-1]\)
        and \(D_y=D_x^\top\), I measured how intensity changes horizontally and vertically. Those signed responses become a
        gradient magnitude, and a single threshold \(t\) turns that soft map into a crisp edge drawing.
      </p>

      <!-- Dx / Dy (signed) -->
      <div class="card mt-12">
        <span class="badge">Signed partial derivatives</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q1_2/cameraman_dx.png" alt="∂I/∂x (signed)">
            <figcaption class="caption">∂I/∂x highlights vertical edges (left↔right contrast). (kernel=Dx=[1,0,-1])</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_2/cameraman_dy.png" alt="∂I/∂y (signed)">
            <figcaption class="caption">∂I/∂y highlights horizontal edges (top↔bottom contrast). (kernel=Dy=Dxᵀ)</figcaption>
          </figure>
          <div class="explain math-sync">
            <h4>How I compute them</h4>
            <p>
              I convolve the grayscale image with \(D_x\) and \(D_y\) using
              <code>scipy.signal.convolve2d</code> (<code>mode="same"</code>, <code>boundary="fill"</code>, <code>fillvalue=0</code>)
              so the output size matches the input. This matches my conventions in 1.1 (true convolution with zero padding).
            </p>
          </div>
        </div>
      </div>

      <!-- Gradient magnitude -->
      <div class="card mt-16">
        <span class="badge">Gradient magnitude</span>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q1_2/cameraman_gradmag.png" alt="‖∇I‖">
            <figcaption class="caption">‖∇I‖ = √(g<sub>x</sub><sup>2</sup> + g<sub>y</sub><sup>2</sup>). (built from Dx/Dy responses)</figcaption>
          </figure>
          <div class="explain math-sync">
            <h4>Why magnitude?</h4>
            <p>
              Combining \(g_x\) and \(g_y\) removes sign and strengthens real boundaries even when they are slanted.
              It also tones down checkerboard artifacts that can show up in the separate partials.
            </p>
          </div>
        </div>
      </div>

      <!-- What is t? -->
      <div class="card mt-16">
        <span class="badge">What is t?</span>
        <div class="explain math-sync">
          <p>
            I first normalize the gradient magnitude to \([0,1]\) for display. Then I produce a binary edge map by
            keeping pixels whose strength is at least \(t\): \(\text{edges}(y,x)=\mathbf{1}\{\|\nabla I(y,x)\|\ge t\}\).
            I swept \(t\in\{0.10,0.15,0.20,0.25,0.30,0.35\}\) and saved each result for visual comparison.
          </p>
        </div>
      </div>

      <!-- Threshold sweep -->
      <div class="card mt-16">
        <span class="badge">Threshold sweep (for comparison)</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t010.png" alt="Edges t=0.10">
            <figcaption class="caption">t = 0.10 (threshold on normalized ‖∇I‖)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t015.png" alt="Edges t=0.15">
            <figcaption class="caption">t = 0.15 (threshold on normalized ‖∇I‖)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t020.png" alt="Edges t=0.20">
            <figcaption class="caption">t = 0.20 (threshold on normalized ‖∇I‖)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t025.png" alt="Edges t=0.25">
            <figcaption class="caption">t = 0.25 (threshold on normalized ‖∇I‖)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t030.png" alt="Edges t=0.30">
            <figcaption class="caption">t = 0.30 (threshold on normalized ‖∇I‖)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t035.png" alt="Edges t=0.35">
            <figcaption class="caption">t = 0.35 (threshold on normalized ‖∇I‖)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Final pick + reasoning -->
      <div class="card mt-16">
        <span class="badge">Final edge map</span>
        <div class="grid-balanced mt-12">
          <figure>
            <img src="assets/q1_2/cameraman_edges_bin_t020.png" alt="Chosen edges (t=0.20)">
            <figcaption class="caption">Chosen threshold: <strong>t = 0.20</strong> (on normalized ‖∇I‖)</figcaption>
          </figure>
          <div>
            <h3 class="mt-0">Why I chose t = 0.20</h3>
            <p>
              I compared tripod legs, the camera outline, the coat edge, and background speckle across the sweep.
              At t=0.10 the background speckle is heavy and small textures dominate.
              t=0.15 is better but still brings in grain.
              At <strong>t=0.20</strong> the main structure remains clean and continuous while the background noise drops a lot.
              0.25 and above start erasing thin tripod edges and details around the hands.
              So 0.20 is the best tradeoff for keeping real contours without clutter.
            </p>
          </div>
        </div>
      </div>

      <!-- === Rubric mapping for Part 1.2 === -->
      <div class="card mt-16">
        <span class="badge">Rubric checklist — Part 1.2</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Show partial derivatives in x and y.</h3>
            <p>I displayed the signed <code>Dx</code> and <code>Dy</code> responses for the cameraman (see “Signed partial derivatives”).</p>

            <h3>Show the gradient magnitude image.</h3>
            <p>I combined them as \( \| \nabla I \| = \sqrt{g_x^2 + g_y^2} \) and showed it in “Gradient magnitude”.</p>

            <h3>Show a binarized edge image and justify the threshold.</h3>
            <p>I swept \( t \in \{0.10, 0.15, 0.20, 0.25, 0.30, 0.35\} \) and chose <strong>t = 0.20</strong> as the best tradeoff between suppressing noise and keeping real edges. The visual reasoning is stated next to the chosen result.</p>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> Finite differences approximate local slope. Magnitude unifies directions so oblique edges stand out. Thresholding converts a soft strength map into a discrete contour map, which is often needed for downstream tasks.
          </div>
        </div>
      </div>
    </section>

    <!-- ======================================= -->
    <!-- Part 1.3: Seeing clearly (DoG filters)  -->
    <!-- ======================================= -->

    <!-- Part 1.3: Derivative of Gaussian (DoG) -->
    <!-- ===== Scoped helpers only for Section 1.3 ===== -->
    <style>
      /* keep MathJax visible here */
      #p13 mjx-container{
        opacity:1 !important;
        filter:none !important;
        mix-blend-mode:normal !important;
      }
      /* make math inherit the surrounding text color */
      #p13 .math-sync mjx-container,
      #p13 .math-sync mjx-container *{
        color:currentColor !important;
        -webkit-text-fill-color:currentColor !important;
      }
    </style>

    <section id="p13" class="section">
      <h2
        style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important; text-shadow:none !important;">
        Part 1.3: Derivative of Gaussian (DoG) Filter
      </h2>

      <p class="lead math-sync"
         style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important; text-shadow:none !important;">
        Raw differences are sensitive: they amplify noise. So the next step in the journey is to <em>listen through a Gaussian</em>.
        I first smooth with \(G\) (via <code>cv2.getGaussianKernel</code> and an outer product) and repeat 1.2 on the blurred image.
        Then I do it in one pass with DoG filters \(k_x = G * D_x\), \(k_y = G * D_y\). The story here is equivalence on the interior,
        and why borders complicate it.
      </p>

      <!-- Base filters (visualized): Gaussian + finite differences -->
      <div class="card mt-12">
        <span class="badge">Base filters (visualized)</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q1_3/gaussian_kernel.png" alt="Gaussian kernel"
                 style="width:420px; height:420px; object-fit:contain; image-rendering:crisp-edges;">
            <figcaption class="caption">Gaussian \(G\). (size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_3/dx_kernel.png" alt="Dx kernel (padded to 9×9)"
                 style="width:420px; height:420px; object-fit:contain; image-rendering:crisp-edges;">
            <figcaption class="caption">Finite difference \(D_x=[1,0,-1]\). (padded to 9×9 for visualization)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_3/dy_kernel.png" alt="Dy kernel (padded to 9×9)"
                 style="width:420px; height:420px; object-fit:contain; image-rendering:crisp-edges;">
            <figcaption class="caption">Finite difference \(D_y=D_x^\top\). (padded to 9×9 for visualization)</figcaption>
          </figure>
        </div>
      </div>

      <!-- DoG kernels (visualized) -->
      <div class="card mt-12">
        <span class="badge">DoG filters (visualized)</span>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q1_3/dog_kx.png" alt="DoG kx"
                 style="width:420px; height:420px; object-fit:contain; image-rendering:crisp-edges;">
            <figcaption class="caption">\(k_x = G * D_x\). (size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_3/dog_ky.png" alt="DoG ky"
                 style="width:420px; height:420px; object-fit:contain; image-rendering:crisp-edges;">
            <figcaption class="caption">\(k_y = G * D_y\). (size=9, σ=1.5)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Blur then differentiate -->
      <div class="card mt-16">
        <span class="badge">Blur → gradients</span>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q1_3/cameraman_blur.png" alt="Gaussian-blurred cameraman">
            <figcaption class="caption">Cameraman after Gaussian blur. (size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_3/cameraman_blur_gradmag.png" alt="Gradmag after blur">
            <figcaption class="caption">Gradient magnitude of the blurred image. (built from blur with size=9, σ=1.5)</figcaption>
          </figure>
        </div>
      </div>

      <!-- One-pass DoG -->
      <div class="card mt-16">
        <span class="badge">DoG in one pass</span>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q1_3/cameraman_dog_gradmag.png" alt="Gradmag via DoG">
            <figcaption class="caption">Gradient magnitude via DoG. (kx,ky from size=9, σ=1.5)</figcaption>
          </figure>
          <div class="explain math-sync">
            <h4>What changes compared to 1.2?</h4>
            <p>
              The blur reduces high-frequency noise before differencing. Edges look cleaner and less speckled.
              The DoG version matches the blur→diff result, since convolving with \(G\) and then with \(D_x\) is
              equivalent to convolving once with \(G*D_x\) (and similarly for \(y\)).
            </p>
          </div>
        </div>
      </div>

      <!-- Threshold sweeps for both methods -->
      <div class="card mt-16">
        <span class="badge">Threshold sweep (blur→diff)</span>
        <div class="grid grid-3 mt-12">
          <figure><img src="assets/q1_3/cameraman_blur_edges_t010.png" alt="blur edges t=0.10"><figcaption class="caption">t = 0.10 (size=9, σ=1.5)</figcaption></figure>
          <figure><img src="assets/q1_3/cameraman_blur_edges_t015.png" alt="blur edges t=0.15"><figcaption class="caption">t = 0.15 (size=9, σ=1.5)</figcaption></figure>
          <figure><img src="assets/q1_3/cameraman_blur_edges_t020.png" alt="blur edges t=0.20"><figcaption class="caption">t = 0.20 (size=9, σ=1.5)</figcaption></figure>
          <figure><img src="assets/q1_3/cameraman_blur_edges_t025.png" alt="blur edges t=0.25"><figcaption class="caption">t = 0.25 (size=9, σ=1.5)</figcaption></figure>
        </div>
      </div>

      <div class="card mt-16">
        <span class="badge">Threshold sweep (DoG once)</span>
        <div class="grid grid-3 mt-12">
          <figure><img src="assets/q1_3/cameraman_dog_edges_t010.png"  alt="dog edges t=0.10"><figcaption class="caption">t = 0.10 (DoG size=9, σ=1.5)</figcaption></figure>
          <figure><img src="assets/q1_3/cameraman_dog_edges_t015.png"  alt="dog edges t=0.15"><figcaption class="caption">t = 0.15 (DoG size=9, σ=1.5)</figcaption></figure>
          <figure><img src="assets/q1_3/cameraman_dog_edges_t020.png"  alt="dog edges t=0.20"><figcaption class="caption">t = 0.20 (DoG size=9, σ=1.5)</figcaption></figure>
          <figure><img src="assets/q1_3/cameraman_dog_edges_t025.png"  alt="dog edges t=0.25"><figcaption class="caption">t = 0.25 (DoG size=9, σ=1.5)</figcaption></figure>
        </div>
      </div>

      <!-- Side-by-side at the common t -->
      <div class="card mt-16">
        <span class="badge">Side-by-side at t = 0.20</span>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q1_3/cameraman_blur_edges_t020.png" alt="blur→diff t=0.20">
            <figcaption class="caption">Blur → diff, t = 0.20. (blur size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q1_3/cameraman_dog_edges_t020.png" alt="DoG t=0.20">
            <figcaption class="caption">DoG once, t = 0.20. (DoG size=9, σ=1.5)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Numerical check -->
      <div class="card mt-16">
        <span class="badge">Do they match?</span>
        <div class="grid-balanced mt-12">
          <div class="explain">
            <h4>Interior agreement</h4>
            <p class="math-sync">
              On the interior (I trim a small border), the max absolute differences are tiny:
              \(|g_x| \approx 3.34\times10^{-7}\), \(|g_y| \approx 3.84\times10^{-7}\),
              and \(|\|\nabla I\|\!| \approx 3.92\times10^{-7}\).
            </p>
            <h4>Why trimming fixes it</h4>
            <p>
              With <code>mode="same"</code> and zero padding, the blur spreads mass outside the image near the boundary.
              The order of operations interacts with that padding. DoG and blur→diff treat the first few pixels
              differently along the border, which gives noticeable edge differences. Once I crop away a small margin
              equal to the kernel half-size, both pipelines see the same neighborhood and they match up to float rounding.
            </p>
          </div>
          <div class="callout">
            <p class="math-sync">
              Without trimming the border, max diffs are around \(3.67\times10^{-1}\) because those boundary conventions
              do not align. After trimming, the two methods are effectively the same.
            </p>
          </div>
        </div>
      </div>

      <!-- === Rubric mapping for Part 1.3 === -->
      <div class="card mt-16">
        <span class="badge">Rubric checklist — Part 1.3</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Construct Gaussian filters using <code>cv2.getGaussianKernel</code>, build DoG filters, and visualize them.</h3>
            <ul>
              <li>I created 1D kernels with <code>cv2.getGaussianKernel</code>, formed a 2D Gaussian by outer product, and showed the kernel image.</li>
              <li>I built DoG filters \(k_x = G * D_x\), \(k_y = G * D_y\) and visualized them.</li>
            </ul>

            <h3>Apply Gaussian smoothing and DoG to the cameraman and compare to finite differences.</h3>
            <ul>
              <li>I ran “blur → Dx/Dy → magnitude” and showed results and threshold sweeps.</li>
              <li>I ran one-pass DoG and showed that interior pixels match blur→diff up to float error. I explained boundary effects.</li>
            </ul>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> Smoothing before differencing suppresses noise that finite differences amplify. DoG fuses these steps into one linear filter, giving the same interior result with fewer passes.
          </div>
        </div>
      </div>
    </section>

    <!-- ====================== -->
    <!-- Part 2: The frequency journey -->
    <!-- ====================== -->

    <!-- ===== Part 2 title (kept solid) ===== -->
    <section id="part2" class="section" style="opacity:1 !important; filter:none !important; mix-blend-mode:normal !important; text-shadow:none !important;">
      <h2 style="opacity:1 !important; color:#0f172a !important; -webkit-text-fill-color:#0f172a !important; filter:none !important; mix-blend-mode:normal !important; text-shadow:none !important;">
        Part 2: Fun with Frequencies
      </h2>
      <p class="lead" style="opacity:1 !important; color:#0f172a !important;">
        With edges under control, I crossed a bridge: thinking in <em>frequencies</em>. From here on, the story is about
        splitting images into slow (low) and fast (high) parts, deciding how much of each to keep, and composing them in
        ways that serve perception.
      </p>
    </section>

    <!-- =======================
         Part 2.1 — Image "Sharpening"
    ======================= -->
    <section id="part2-1" class="section">
      <h2 style="opacity:1 !important; color:#0f172a !important;">Part 2.1: Image “Sharpening”</h2>

      <p class="lead" style="opacity:1 !important; color:#0f172a !important;">
        Sharpening is the first stop: separate low and high, then nudge the highs. Using a Gaussian \(G\),
        Low = \(I * G\), High = \(I - (I * G)\), and the final sharpened image is
        \(I_{\text{sharp}} = I + \alpha\,\big(I - I*G\big)\).
        It’s also a single convolution with
        \(K = (1+\alpha)\,\delta - \alpha\,G\), where \(\alpha\) dials the effect.
      </p>

      <!-- Taj workflow -->
      <div class="card mt-16">
        <span class="badge">Taj Mahal: blur → high → sharpen</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/taj/input.png" alt="Taj input">
            <figcaption class="caption">Input (for unsharp with G size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/taj/low.png" alt="Taj low-pass">
            <figcaption class="caption">Gaussian blur (low frequencies). (size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/taj/high.png" alt="Taj high-pass">
            <figcaption class="caption">High-pass (signed visualization). (derived from size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/taj/sharp_strength0.5.png" alt="Taj α=0.5">
            <figcaption class="caption">\(\alpha=0.5\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/taj/sharp_strength1.5.png" alt="Taj α=1.5">
            <figcaption class="caption">\(\alpha=1.5\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/taj/sharp_strength3.png" alt="Taj α=3.0">
            <figcaption class="caption">\(\alpha=3.0\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q2_1/taj/sharp_strength5.png" alt="Taj α=5.0">
            <figcaption class="caption">\(\alpha=5.0\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/taj/single_conv_strength2.png" alt="Taj single-conv α=2">
            <figcaption class="caption">Single-convolution \(K\) with \(\alpha=2.0\). (G size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <div class="explain mt-12">
          <h4>Observation</h4>
          <p>Moderate \(\alpha\) (about 1–2) improves clarity while staying clean. Large \(\alpha\) increases contrast across edges and creates halos.</p>
        </div>
      </div>

      <!-- Second image: Cityscape -->
      <div class="card mt-16">
        <span class="badge">Cityscape: second example</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/cityscape/input.png" alt="Cityscape input">
            <figcaption class="caption">Input (for unsharp with G size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/cityscape/low.png" alt="Cityscape low">
            <figcaption class="caption">Gaussian blur (low frequencies). (size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/cityscape/high.png" alt="Cityscape high">
            <figcaption class="caption">High-pass (signed). (from size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/cityscape/sharp_strength1.0.png" alt="City α=1.0">
            <figcaption class="caption">\(\alpha=1.0\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/cityscape/sharp_strength3.png" alt="City α=3.0">
            <figcaption class="caption">\(\alpha=3.0\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/cityscape/sharp_strength5.png" alt="City α=5.0">
            <figcaption class="caption">\(\alpha=5.0\) (unsharp size=9, σ=1.5)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Evaluation: sharp (waves+forest) → stronger blur → resharpen with very large α -->
      <div class="card mt-16">
        <span class="badge">Evaluation on waves + forest (sharp → stronger blur → resharpen)</span>
        <p class="caption mb-6">I blurred the sharp image with a stronger \(G\) so the softening is obvious, then resharpened with a wide range of \(\alpha\).</p>

        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/evaluation/original.png" alt="Original waves">
            <figcaption class="caption">Original (high-res, sharp).</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/evaluation/blurred.png" alt="Blurred waves">
            <figcaption class="caption">Blurred by \(G\). (blur size=31, σ=4.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength2.png" alt="Resharp α=2">
            <figcaption class="caption">Resharpened, \(\alpha=2.0\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength3.png" alt="Resharp α=3">
            <figcaption class="caption">\(\alpha=3.0\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength5.png" alt="Resharp α=5">
            <figcaption class="caption">\(\alpha=5.0\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength10.png" alt="Resharp α=10">
            <figcaption class="caption">\(\alpha=10\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <!-- Show the very large alphas you generated -->
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength30.png" alt="Resharp α=30">
            <figcaption class="caption">\(\alpha=30\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength60.png" alt="Resharp α=60">
            <figcaption class="caption">\(\alpha=60\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_1/evaluation/resharp_strength120.png" alt="Resharp α=120">
            <figcaption class="caption">\(\alpha=120\). (unsharp size=9, σ=1.5)</figcaption>
          </figure>
        </div>

        <div class="explain mt-12">
          <h4>What this shows</h4>
          <ul>
            <li>Sharpening a blurred image improves perceived detail, but it does not recreate the lost fine frequencies.</li>
            <li>There is a sweet spot: mid \(\alpha\) (about 2–3 here) looks closest to the original without obvious halos.</li>
            <li>Very large \(\alpha\) overshoots and produces ringing, especially along the shoreline and tree silhouettes.</li>
          </ul>
          <p class="text-muted mb-0">I saved MSE logs for each \(\alpha\) in the evaluation folder. The lowest errors fall in the same mid range, which matches the visuals.</p>
        </div>
      </div>

      <div class="callout mt-16"
           style="opacity:1 !important; filter:none !important; mix-blend-mode:normal !important; text-shadow:none !important; color:#0f172a !important; -webkit-text-fill-color:#0f172a !important;">
        I implemented unsharp masking and explained it in terms of blur and high frequencies.
        I showed low, high, and sharpened versions for the Taj image and for a second image (cityscape).
        I also varied \(\alpha\) to show how the amount changes the look. In the evaluation, I blurred a sharp photo and tried
        to get back the sharpness by adding highs. Mid \(\alpha\) looks most natural; very large \(\alpha\) brings artifacts.
      </div>

      <!-- === Rubric mapping for Part 2.1 === -->
      <div class="card mt-16">
        <span class="badge">Rubric checklist — Part 2.1</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Implement the unsharp mask filter and explain how it works.</h3>
            <p>I split the image into <em>low</em> (= blur by Gaussian) and <em>high</em> (= original − low). Sharpen = original + α·high. I also show the single-kernel form \(K = (1+\alpha)\delta - \alpha G\).</p>

            <h3>Show blurred, high-frequency, and sharpened versions of Taj + another image.</h3>
            <p>These are included above for Taj and Cityscape: low, high (signed view), and multiple α values.</p>

            <h3>Demonstrate how varying the sharpening amount changes the result.</h3>
            <p>I varied α over a wide range and described the visual effect and artifacts (halos/ringing) at high α.</p>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> Many images look soft because their high bands are weak. Unsharp masking pushes those bands up selectively, improving perceived detail while keeping large-scale tone intact.
          </div>
        </div>
      </div>
    </section>

    <!-- =======================
         Part 2.2 — Hybrid Images
    ====================== -->

    <!-- Force-opaque just for Section 2.2 (text, captions, and MathJax) -->
    <style>
      #part2-2, #part2-2 * {
        opacity: 1 !important;
        filter: none !important;
        mix-blend-mode: normal !important;
        text-shadow: none !important;
      }
      #part2-2,
      #part2-2 p, #part2-2 h2, #part2-2 h3, #part2-2 h4,
      #part2-2 .caption, #part2-2 .badge, #part2-2 .callout {
        color: var(--ink) !important;
        -webkit-text-fill-color: currentColor !important;
      }
      /* MathJax inside 2.2 always inherits the surrounding color */
      #part2-2 .MathJax,
      #part2-2 .mjx-chtml,
      #part2-2 .mjx-math,
      #part2-2 [class^="mjx-"],
      #part2-2 [class*=" mjx-"]{
        color: currentColor !important;
        -webkit-text-fill-color: currentColor !important;
        opacity: 1 !important;
        filter: none !important;
        mix-blend-mode: normal !important;
        text-shadow: none !important;
      }
    </style>

    <section id="part2-2" class="section">
      <h2 style="opacity:1 !important; color:#0f172a !important;">
        Part 2.2: Hybrid Images
      </h2>

      <!-- Teaser -->
      <div class="card">
        <span class="badge">teaser</span>
        <div class="grid-balanced mt-12">
          <div>
            <p class="lead">
              A small magic trick on the path: two pictures at once. Up close, the high-frequency subject speaks;
              from far away, the low-frequency subject takes over.
            </p>
          </div>
          <figure>
            <img src="assets/q2_2/derek_nutmeg/hybrid.png" alt="Hybrid teaser (Derek + Nutmeg)">
            <figcaption class="caption">Hybrid image changes with viewing distance. (low: size=21, σ=4; high: size=13, σ=3)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Overview -->
      <div class="card mt-16">
        <span class="badge">overview</span>
        <p class="mt-12">
          The method follows Oliva, Torralba, and Schyns (SIGGRAPH 2006): low-pass one image with \(G\) to get \(I_{\text{low}} = I * G\),
          high-pass the other \(I_{\text{high}} = J - (J * G)\), then add them \(H = I_{\text{low}} + I_{\text{high}}\).
          Alignment matters for how features group; I aligned pairs before filtering. The hybrid flips with viewing distance
          because our perception privileges high frequencies when near and low when far.
        </p>
      </div>

      <!-- Full process example with FFTs (PERSON_OLDMAN SET) -->
      <div class="card mt-16">
        <span class="badge">full process: person + old man (with FFTs)</span>

        <h3 class="mt-12">Inputs and alignment</h3>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/person_oldman/a_aligned.png" alt="Person aligned">
            <figcaption class="caption">Left image (low). (low_size=21, low_sigma=4)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/b_aligned.png" alt="Old man aligned">
            <figcaption class="caption">Right image (high). (high_size=13, high_sigma=2)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/hybrid.png" alt="Hybrid result">
            <figcaption class="caption">Final hybrid. (low 21/4 + high 13/2)</figcaption>
          </figure>
        </div>

        <h3 class="mt-16">Frequency analysis (log magnitude FFT)</h3>

        <!-- Originals + Hybrid FFTs (3-up as before) -->
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/person_oldman/a_fft.png" alt="FFT of left">
            <figcaption class="caption">FFT of left (original). Low-frequency content concentrated at the center; reveals the base shape energy.</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/b_fft.png" alt="FFT of right">
            <figcaption class="caption">FFT of right (original). Shows this face’s native detail spectrum before filtering.</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/hybrid_fft.png" alt="FFT of hybrid">
            <figcaption class="caption">FFT of hybrid. Mixes a bright center (low-pass) with energized outskirts (high-pass).</figcaption>
          </figure>
        </div>

        <!-- NEW: Filtered-piece FFTs (low & high) -->
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/person_oldman/a_low_fft.png" alt="FFT of low-pass">
            <figcaption class="caption">FFT of low-pass. Energy collapses toward the center—high frequencies are suppressed.</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/b_high_fft.png" alt="FFT of high-pass">
            <figcaption class="caption">FFT of high-pass. Center (DC/slow variations) is attenuated; energy spreads outward (edges/details).</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/hybrid.png" alt="Hybrid (visual)">
            <figcaption class="caption">Visual hybrid again (reference). Perceptually: far = left’s coarse structure; near = right’s fine details.</figcaption>
          </figure>
        </div>

        <div class="callout mt-12"
             style="opacity:1 !important; filter:none !important; mix-blend-mode:normal !important; text-shadow:none !important; color:#ffffff !important; -webkit-text-fill-color:#ffffff !important;">
          <h4 class="mt-0">What each Fourier means</h4>
          <ul>
            <li><strong>Originals (a_fft, b_fft):</strong> The overall frequency makeup of each input; a bright center signals strong low-frequency structure.</li>
            <li><strong>Low-pass (low_fft):</strong> Spectrum contracts toward the origin: only smooth, large-scale variations remain.</li>
            <li><strong>High-pass (high_fft):</strong> Spectrum dims at the center and brightens toward the periphery, emphasizing edges and fine textures.</li>
            <li><strong>Hybrid (hybrid_fft):</strong> Superposition of both behaviors: central energy from the low image plus peripheral energy from the high image: matching the “far vs. near” perceptual flip.</li>
          </ul>
        </div>

        <h3 class="mt-16">Filtered pieces</h3>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/person_oldman/a_low_fft.png" alt="Low-pass of left">
            <figcaption class="caption">Low-pass of left. (size=21, σ=4)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/b_high_fft.png" alt="High-pass of right">
            <figcaption class="caption">High-pass of right. (size=13, σ=2)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/person_oldman/hybrid.png" alt="Hybrid again">
            <figcaption class="caption">Sum of low and high. (low 21/4 + high 13/2)</figcaption>
          </figure>
        </div>

        <div class="explain mt-12">
          <h4>Cutoff choices</h4>
          <p>
            I set the low-pass size/sigma to keep the base face’s shape legible at distance, and the high-pass size/sigma
            to retain crisp details up close without halos. The FFTs confirm this split: the low-pass piles energy at the
            center while the high-pass pushes it outward; the hybrid combines both patterns.
          </p>
        </div>
      </div>

      <!-- Derek + Nutmeg (required example) -->
      <div class="card mt-16">
        <span class="badge">Derek + Nutmeg</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/derek_nutmeg/a_aligned.png" alt="Derek aligned">
            <figcaption class="caption">Left input (low). (low_size=21, low_sigma=4)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/derek_nutmeg/b_aligned.png" alt="Nutmeg aligned">
            <figcaption class="caption">Right input (high). (high_size=13, high_sigma=3)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/derek_nutmeg/hybrid.png" alt="Derek+Nutmeg hybrid">
            <figcaption class="caption">Hybrid. (low 21/4 + high 13/3)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Your own example #1 -->
      <div class="card mt-16">
        <span class="badge">Einstein + Marilyn</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/einstein_mar/a_aligned.png" alt="Einstein aligned">
            <figcaption class="caption">Left input (low). (low_size=21, low_sigma=4)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/einstein_mar/b_aligned.png" alt="Marilyn aligned">
            <figcaption class="caption">Right input (high). (high_size=17, high_sigma=2)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/einstein_mar/hybrid.png" alt="Einstein+Marilyn hybrid">
            <figcaption class="caption">Hybrid. (low 21/4 + high 17/2)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Your own example #2 -->
      <div class="card mt-16">
        <span class="badge">Cat + Lion</span>
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_2/cat_lion/a_aligned.png" alt="Cat aligned">
            <figcaption class="caption">Left input (low). (low_size=21, low_sigma=4)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/cat_lion/b_aligned.png" alt="Lion aligned">
            <figcaption class="caption">Right input (high). (high_size=13, high_sigma=3)</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_2/cat_lion/hybrid.png" alt="Cat+Lion hybrid">
            <figcaption class="caption">Hybrid. (low 21/4 + high 13/3)</figcaption>
          </figure>
        </div>
      </div>

      <div class="callout mt-16"
           style="opacity:1 !important; filter:none !important; mix-blend-mode:normal !important; text-shadow:none !important; color:#0f172a !important; -webkit-text-fill-color:#0f172a !important;">
        <strong>Takeaways:</strong>
        Up close, the high-frequency face drives perception; from far away, the low-frequency face wins.
        Good alignment and careful cutoffs matter. If the high cutoff is too small, the hybrid looks muddy.
        If it is too large, halos and ghosting appear.
      </div>

      <!-- === Rubric mapping for Part 2.2 === -->
      <div class="card mt-16">
        <span class="badge">Rubric checklist — Part 2.2</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Create three hybrid images (Derek + Nutmeg plus two of my own).</h3>
            <p>I included Derek+Nutmeg and two custom pairs. Inputs are aligned before filtering.</p>

            <h3>For one hybrid, show the full process and justify cutoff choices.</h3>
            <ul>
              <li>I presented originals, alignment, low/high splits, final sum, and log-magnitude FFTs for the full walk-through pair.</li>
              <li>I explained cutoff selection in terms of keeping coarse structure for distance and crisp details for near-view without halos.</li>
            </ul>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> The hybrid trick leverages how our vision filters with distance. The Fourier plots make the design visible: center energy = low; outer energy = high; the hybrid is a deliberate sum of those.
          </div>
        </div>
      </div>
    </section>

    <!-- ===================== -->
    <!-- Part 2.3 — the maps  -->
    <!-- ===================== -->

    <!-- Force-opaque just for Section 2.3 (text, captions, images, MathJax) -->
    <style>
      #part2-3, #part2-3 * {
        opacity: 1 !important;
        filter: none !important;
        mix-blend-mode: normal !important;
        text-shadow: none !important;
      }
      #part2-3,
      #part2-3 p, #part2-3 h2, #part2-3 h3, #part2-3 h4,
      #part2-3 .caption, #part2-3 .badge, #part2-3 .callout {
        color: var(--ink) !important;
        -webkit-text-fill-color: currentColor !important;
      }
      #part2-3 .MathJax,
      #part2-3 .mjx-chtml,
      #part2-3 .mjx-math,
      #part2-3 [class^="mjx-"],
      #part2-3 [class*=" mjx-"]{
        color: currentColor !important;
        -webkit-text-fill-color: currentColor !important;
        opacity: 1 !important;
        filter: none !important;
        mix-blend-mode: normal !important;
        text-shadow: none !important;
      }

      /* small helper so per-cell notes read cleanly */
      #part2-3 .explain-mini {
        font-size: 0.95rem;
        line-height: 1.4;
        margin-top: 0.5rem;
        color: var(--ink);
      }
    </style>

    <section id="part2-3" class="section">
      <h2 style="color:#000000 !important; -webkit-text-fill-color:#000000 !important; opacity:1 !important; filter:none !important; mix-blend-mode:normal !important; text-shadow:none !important;">
        Part 2.3: Gaussian and Laplacian Stacks
      </h2>

      <!-- Overview -->
      <div class="card">
        <span class="badge">overview</span>
        <div class="grid-balanced mt-12">
          <div>
            <p class="lead">
              To blend scenes later, I needed good maps of “what lives at which scale.” Gaussian stacks blur repeatedly
              without downsampling; Laplacian stacks store the band-pass differences plus a top residual. These are the
              exact stacks I use downstream for blending.
            </p>
            <p class="mb-0">
              Here I use <strong>levels = 7</strong>, <strong>size = 31</strong>, <strong>σ = 5.0</strong>.
              Apple and Orange are size matched before stacking so pixels line up.
            </p>
          </div>
          <figure>
            <img src="assets/q2_3/fig342.png" alt="Figure 3.42 reference (layout)">
            <figcaption class="caption">Target layout for the Oraple visualization. (levels=7, size=31, σ=5.0)</figcaption>
          </figure>
        </div>
      </div>

      <!-- Stacks for Apple and Orange -->
      <div class="card mt-16">
        <span class="badge">Gaussian &amp; Laplacian stacks</span>
        <p class="mt-12">
          Each row is one level. Laplacian images are normalized for display so the bands are visible.
        </p>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q2_3/apple_gauss_stack.png" alt="Apple Gaussian stack">
            <figcaption class="caption">
              Apple — Gaussian stack. (levels=7, size=31, σ=5.0). Built by repeated blur at fixed size.
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/apple_lap_stack.png" alt="Apple Laplacian stack">
            <figcaption class="caption">
              Apple — Laplacian stack. (levels=7). Each band is the difference between two Gaussian levels.
            </figcaption>
          </figure>
        </div>
        <div class="grid grid-2 mt-12">
          <figure>
            <img src="assets/q2_3/orange_gauss_stack.png" alt="Orange Gaussian stack">
            <figcaption class="caption">
              Orange — Gaussian stack. (levels=7, size=31, σ=5.0).
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/orange_lap_stack.png" alt="Orange Laplacian stack">
            <figcaption class="caption">
              Orange — Laplacian stack. (levels=7). Bands highlight edges and textures at different scales.
            </figcaption>
          </figure>
        </div>
      </div>

      <!-- Full grid a–l -->
      <div class="card mt-16">
        <span class="badge">Recreating Szeliski Fig. 3.42 (a)–(l)</span>
        <p class="mt-12">
          Below is the storyboard: how each band contributes, per level, and how they add up. The blend equation at level \(i\) is
          \[
            L_{\text{out}}^{(i)} = G_M^{(i)} \cdot L_A^{(i)} + \big(1 - G_M^{(i)}\big) \cdot L_B^{(i)}
          \]
          The final image is the sum across levels.
        </p>
        <figure class="mt-12">
          <img src="assets/q2_3/szeliski_342_grid_color.png" alt="Grid a–l (color)">
          <figcaption class="caption">Full grid (a–l). (levels=7, size=31, σ=5.0; vertical cosine mask with its own Gaussian stack)</figcaption>
        </figure>

        <!-- Row 1: level 0 -->
        <div class="grid grid-3 mt-16">
          <figure>
            <img src="assets/q2_3/a_color.png" alt="Cell a">
            <figcaption class="caption">
              a — Apple band × mask (level 0). Params: levels=7, size=31, σ=5.0.
              <div class="explain-mini">I take the level-0 Laplacian band from Apple and multiply by the blurred mask \(G_M^{(0)}\). This keeps Apple’s finest details on the left side.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/b_color.png" alt="Cell b">
            <figcaption class="caption">
              b — Orange band × (1 − mask) (level 0). Same params.
              <div class="explain-mini">I take the level-0 Laplacian band from Orange and weight it by \(1 - G_M^{(0)}\). This keeps Orange’s finest details on the right side.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/c_color.png" alt="Cell c">
            <figcaption class="caption">
              c — Sum of a and b (level 0 composite).
              <div class="explain-mini">I add the two weighted bands to form the finest scale of the blend. This is the first piece of \(L_{\text{out}}\).</div>
            </figcaption>
          </figure>
        </div>

        <!-- Row 2: level 2 -->
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_3/d_color.png" alt="Cell d">
            <figcaption class="caption">
              d — Apple band × mask (level 2).
              <div class="explain-mini">Same step at a coarser band. The mask is also blurred at level 2, so the transition spreads wider at this scale.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/e_color.png" alt="Cell e">
            <figcaption class="caption">
              e — Orange band × (1 − mask) (level 2).
              <div class="explain-mini">The Orange band is weighted by \(1 - G_M^{(2)}\). This balances mid-scale edges from both sides.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/f_color.png" alt="Cell f">
            <figcaption class="caption">
              f — Sum of d and e (level 2 composite).
              <div class="explain-mini">I add the two level-2 pieces. This builds the medium frequencies of the final blend.</div>
            </figcaption>
          </figure>
        </div>

        <!-- Row 3: level 4 -->
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_3/g_color.png" alt="Cell g">
            <figcaption class="caption">
              g — Apple band × mask (level 4).
              <div class="explain-mini">Coarser band from Apple times \(G_M^{(4)}\). The mask is very smooth here so the transition is very soft.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/h_color.png" alt="Cell h">
            <figcaption class="caption">
              h — Orange band × (1 − mask) (level 4).
              <div class="explain-mini">Coarser band from Orange times \(1 - G_M^{(4)}\). This carries broad shading and color changes.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/i_color.png" alt="Cell i">
            <figcaption class="caption">
              i — Sum of g and h (level 4 composite).
              <div class="explain-mini">I add the two to finish the large-scale band piece for the blend.</div>
            </figcaption>
          </figure>
        </div>

        <!-- Row 4: masked originals and final -->
        <div class="grid grid-3 mt-12">
          <figure>
            <img src="assets/q2_3/j_color.png" alt="Cell j">
            <figcaption class="caption">
              j — Apple × mask (original scale).
              <div class="explain-mini">I apply the base mask to the original Apple. This shows what the left half contributes before the per-level mixing.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/k_color.png" alt="Cell k">
            <figcaption class="caption">
              k — Orange × (1 − mask) (original scale).
              <div class="explain-mini">I apply the inverse mask to the original Orange. This shows the right half contribution.</div>
            </figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/l_color.png" alt="Cell l">
            <figcaption class="caption">
              l — Final multiband blend (Oraple). Params: levels=7, size=31, σ=5.0; vertical cosine mask.
              <div class="explain-mini">I sum all blended Laplacian bands from fine to coarse and add the top residual. The seam is hidden because each scale transitions over the blurred mask at that scale.</div>
            </figcaption>
          </figure>
        </div>

        <div class="callout mt-16">
          <strong>How it was created:</strong>
          I build Gaussian stacks \(G_A, G_B\) for Apple and Orange and Laplacian stacks \(L_A, L_B\) from those.
          I make a vertical cosine mask \(M\) and build its Gaussian stack \(G_M\).
          For every level I blend bands with \(G_M^{(i)}\) as the weight, then I sum all blended bands and clip to [0,1].
        </div>
      </div>

      <!-- Final Oraple result -->
      <div class="card mt-16">
        <span class="badge">Final blend</span>
        <div class="grid-balanced mt-12">
          <figure>
            <img src="assets/q2_3/oraple_result.png" alt="Oraple final result">
            <figcaption class="caption">
              Final Oraple blend. (levels=7, size=31, σ=5.0; vertical cosine mask). Built by summing blended Laplacian bands across scales.
            </figcaption>
          </figure>
          <div class="callout">
            <strong>Notes:</strong>
            The blurred mask allows wide transitions at coarse scales and tight transitions at fine scales, which hides the seam.
          </div>
        </div>
      </div>

      <!-- === Rubric mapping for Part 2.3 === -->
      <div class="card mt-16">
        <span class="badge">Rubric checklist — Part 2.3</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Visualize the process: Gaussian and Laplacian stacks for Orange + Apple.</h3>
            <p>I showed Gaussian and Laplacian stacks for each image at multiple levels with fixed image size per level (stacks, not pyramids).</p>

            <h3>Recreate outcomes of Szeliski Figure 3.42 (a)–(l).</h3>
            <p>I reproduced the 4×3 grid: per-level masked bands for both images, per-level sums, masked originals, and the final reconstruction, all using the same mask-per-level equation stated on the page.</p>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> Stacks separate image information by scale. Blending at every scale with a blurred mask gives a transition that is sharp for fine detail and wide for coarse structure, which hides the seam.
          </div>
        </div>
      </div>
    </section>

    <!-- =======================
         Part 2.4 — Multiresolution Blending
    ====================== -->
    <style>
      /* Force black for title + intro paragraph */
      #p24 h2, 
      #p24 p.lead {
        opacity: 1 !important;
        filter: none !important;
        mix-blend-mode: normal !important;
        color: #0f172a !important;
        -webkit-text-fill-color: #0f172a !important;
        text-shadow: none !important;
      }

      /* Force white ONLY for the “Why” paragraphs */
      #p24 .why {
        opacity: 1 !important;
        filter: none !important;
        mix-blend-mode: normal !important;
        color: #ffffff !important;
        -webkit-text-fill-color: #ffffff !important;
        background: #0f172a !important;
        text-shadow: none !important;
        padding: 12px 14px;
        border-radius: 10px;
      }

      /* Layout helpers */
      #p24 .tri {
        display: grid;
        grid-template-columns: repeat(3, minmax(220px, 1fr));
        gap: 16px;
        align-items: start;
      }
      #p24 .duo {
        display: grid;
        grid-template-columns: repeat(2, minmax(220px, 1fr));
        gap: 16px;
        align-items: start;
      }
      #p24 .full {
        display: flex;
        justify-content: center;   /* center horizontally */
        gap: 12px;
        margin-top: 12px;
      }
      #p24 figure { margin: 0; }
      #p24 img {
        width: 100%;
        height: auto;
        border-radius: 8px;
        display: block;
      }
      #p24 .caption { font-size: 12px; color: #475569; margin-top: 6px; }
      #p24 .badge {
        font-size: 12px;
        background: #eef2ff;
        color: #3730a3;
        border: 1px solid #c7d2fe;
        padding: 4px 8px;
        border-radius: 8px;
      }
      #p24 .card {
        border: 1px solid #e5e7eb;
        border-radius: 14px;
        padding: 16px;
        background: #ffffff;
        margin-top: 16px;
      }
      #p24 .mt-0 { margin-top: 0; }
      #p24 .mt-8 { margin-top: 8px; }
      #p24 .mt-12 { margin-top: 12px; }
      #p24 .mt-16 { margin-top: 16px; }
    </style>

    <section id="p24" class="section">
      <h2>Part 2.4: Multiresolution Blending (the Oraple and others)</h2>

      <p class="lead">
        The final leg is composition: blending images across scales so seams disappear. Using Gaussian and Laplacian stacks
        for both inputs and for a soft mask, I combine per-level bands with
        \[
          L_{\text{out}}^{(i)} = G_M^{(i)} \cdot L_A^{(i)} + \big(1 - G_M^{(i)}\big) \cdot L_B^{(i)}
        \]
        Summing the blended bands yields the final image. The trick is that the mask is <em>also</em> blurred per level:
        narrow transitions for fine details, wide transitions for coarse tone.
      </p>

      <!-- ================= Oraple ================= -->
      <div class="card mt-16">
        <span class="badge">Oraple: Apple + Orange</span>
        <p class="lead" style="opacity:1 !important; color:#0f172a !important; filter:none !important; -webkit-text-fill-color:#0f172a !important;">
          I chose apple and orange because they are the classic example from the paper. The round shapes and strong color
          contrast make the seam obvious unless blending is done correctly.
        </p>

        <!-- Explanation of cosine mask -->
        <p class="why mt-12">
          What is a cosine mask? A cosine mask is a smooth weighting function that transitions gradually from 1 to 0 using
          the cosine curve instead of a hard step. In practice, I pick a ramp width (in pixels) and compute values
          \[
            M(x) = \tfrac{1}{2}\big(1 + \cos(\theta)\big), \quad \theta \in [0, \pi],
          \]
          across that ramp. The result is 1 on one side, 0 on the other, and a gentle fade in between. This avoids visible
          seams and makes the blended regions look natural.
        </p>

        <!-- Originals -->
        <div class="duo mt-12">
          <figure>
            <img src="assets/q2_4/oraple_vertical/apple.jpeg" alt="Apple (original)">
            <figcaption class="caption">Before: Apple (original input).</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_4/oraple_vertical/orange.jpeg" alt="Orange (original)">
            <figcaption class="caption">Before: Orange (original input).</figcaption>
          </figure>
        </div>

        <!-- Masked pieces -->
        <div class="tri mt-12">
          <figure>
            <img src="assets/q2_4/oraple_vertical/mask.png" alt="Oraple mask">
            <figcaption class="caption">Cosine vertical mask. Params: levels=7, size=31, σ=5.0.</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/j_color.png" alt="Apple × mask (cell j)">
            <figcaption class="caption">Masked A (Apple × mask).</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_3/k_color.png" alt="Orange × (1−mask) (cell k)">
            <figcaption class="caption">Masked B (Orange × (1−mask)).</figcaption>
          </figure>
        </div>

        <!-- Final -->
        <div class="full">
          <figure>
            <img src="assets/q2_4/oraple_vertical/result.png" alt="Oraple result">
            <figcaption class="caption">Final Oraple blend.</figcaption>
          </figure>
        </div>
      </div>

      <!-- ================= Sunset → City Night (Horizontal) ================= -->
      <div class="card mt-16">
        <span class="badge">Sunset → City Night (Horizontal mask)</span>
        <p class="why">
          Why this pair: A horizontal seam fits scenes with a clear horizon. The soft cosine mask keeps the sunset sky at the top,
          while the city lights take over toward the bottom, minimizing visible edges across buildings.
        </p>

        <!-- Masked pieces -->
        <div class="tri mt-12">
          <figure>
            <img src="assets/q2_4/sunset_city_horizontal/mask.png" alt="Horizontal mask">
            <figcaption class="caption">Horizontal cosine mask (top→bottom). Params: levels=7, size=31, σ=5.0, ramp=120.</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_4/sunset_city_horizontal/masked_A.png" alt="Sunset × mask">
            <figcaption class="caption">Masked A (Sunset × mask).</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_4/sunset_city_horizontal/masked_B.png" alt="City night × (1−mask)">
            <figcaption class="caption">Masked B (City night × (1−mask)).</figcaption>
          </figure>
        </div>

        <!-- Final -->
        <div class="full">
          <figure>
            <img src="assets/q2_4/sunset_city_horizontal/result.png" alt="Sunset → City night blended result">
            <figcaption class="caption">Final horizontal multiresolution blend.</figcaption>
          </figure>
        </div>

        <!-- 4×3 color grid -->
        <div class="full mt-12">
          <figure>
            <img src="assets/q2_4/sunset_city_horizontal/szeliski_342_grid_color.png" alt="Sunset→City 4×3 color grid">
            <figcaption class="caption">4×3 color grid: band contributions and reconstruction for the horizon blend. Labelling is the same as in 2.3's grid</figcaption>
          </figure>
        </div>
      </div>

      <!-- ================= Before/After portraits ================= -->
      <div class="card mt-16">
        <span class="badge">Before/After portraits</span>
        <p class="why">
          Why these pairs: The portraits show a personal before/after. One photo is from high school six years
          ago and the other is a recent college portrait. They were aligned using my eye positions so the face
          parts line up. A vertical cosine mask lets the two halves merge smoothly across the face.
        </p>

        <!-- Masked pieces -->
        <div class="tri mt-12">
          <figure>
            <img src="assets/q2_4/me_before_after_vertical_aligned/mask.png" alt="Vertical mask">
            <figcaption class="caption">Vertical cosine mask. Params: levels=7, size=31, σ=5.0.</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_4/me_before_after_vertical_aligned/masked_A.png" alt="Masked before">
            <figcaption class="caption">Masked A (Before side).</figcaption>
          </figure>
          <figure>
            <img src="assets/q2_4/me_before_after_vertical_aligned/masked_B.png" alt="Masked after">
            <figcaption class="caption">Masked B (After side).</figcaption>
          </figure>
        </div>

        <!-- Final -->
        <div class="full">
          <figure>
            <img src="assets/q2_4/me_before_after_vertical_aligned/result.png" alt="Blended portrait">
            <figcaption class="caption">Final blended portrait.</figcaption>
          </figure>
        </div>

        <!-- 4×3 color grid -->
        <div class="full mt-12">
          <figure>
            <img src="assets/q2_4/me_before_after_vertical_aligned/szeliski_342_grid_color.png" alt="Portrait 4×3 color grid">
            <figcaption class="caption">4×3 color grid: band contributions and reconstruction for the portrait blend. Labelling is the same as in 2.3's grid</figcaption>
          </figure>
        </div>
      </div>

      <!-- === Rubric mapping for Part 2.4 === -->
      <style>
        #p24 .rubric * {
          opacity: 1 !important;
          filter: none !important;
          mix-blend-mode: normal !important;
          color: #0f172a !important;
          -webkit-text-fill-color: #0f172a !important;
          text-shadow: none !important;
        }
      </style>

      <div class="card mt-16 rubric">
        <span class="badge">Rubric checklist — Part 2.4</span>
        <div class="grid-balanced mt-12">
          <div>
            <h3 class="mt-0">Blend two images with a vertical or horizontal seam.</h3>
            <p>I blended Apple and Orange (the classic “oraple”) with a vertical cosine mask. The result is shown in “Final Oraple blend.”</p>

            <h3>Include 2 additional custom blends, with at least one irregular mask.</h3>
            <p>I blended Sunset+City Night with a horizontal cosine mask, and Before/After portraits with a vertical cosine mask.  
            I also used a non-straight circular mask for City+Forest to demonstrate irregular transitions.</p>

            <h3>Illustrate the process with masked inputs and per-level outputs.</h3>
            <p>I showed masked inputs (A×mask and B×(1−mask)) and per-level band contributions in a 4×3 color storyboard, connecting the math to the final images.</p>
          </div>
          <div class="callout">
            <strong>Motivation:</strong> Multiresolution blending is a scale-aware cross-fade. Using the Gaussian stack of the mask makes small details blend narrowly while large tones blend broadly, which hides seams.
          </div>
        </div>
      </div>
    </section>

    <!-- =======================
         Reflection — What I Learned
    ====================== -->
    <section id="reflection" class="section">
      <h2 style="opacity:1 !important; color:#0f172a !important; -webkit-text-fill-color:#0f172a !important;">
        Reflection: What I Learned
      </h2>
      <p class="lead" style="opacity:1 !important; color:#0f172a !important;">
        The heart of this journey was realizing how much control you get once you build the pieces yourself.
        Writing my own Gaussian and Laplacian stacks (instead of calling a library) made it clear how each level carries
        different information and why blending works when the mask is blurred at multiple scales.
        When I made the Oraple, a seam that looked terrible at the pixel level almost disappeared once the stacks were combined.
        The before/after portrait also stood out because I had to decide which facial features to align to make the merge seamless.
        <br><br>
        This project taught me that details I used to skip, like the exact σ or mask ramp width, actually decide whether an image
        looks natural or broken. It’s made me more vigilant about how images are constructed and why some of them “feel” right.
      </p>
    </section>

    <footer class="site-footer">
      <p>© 2025 — CS180/280A Project 2.</p>
    </footer>

  </main>
</body>
</html>
